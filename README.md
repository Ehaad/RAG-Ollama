# RAG-Ollama
# ğŸ“š RAG-based Document Retrieval  

A **Retrieval-Augmented Generation (RAG) pipeline** built using **Streamlit, FAISS, and LLMs (Ollama / OpenAI)**.  
This project enables **efficient document search and intelligent Q&A** from custom datasets or web pages.  

---

## ğŸš€ Features  
- ğŸ” **Document Retrieval** using FAISS vector database  
- ğŸ§© **Text Chunking** with RecursiveCharacterTextSplitter for better context handling  
- ğŸ”— **Chains & Retrieval** â€“ integrates retriever with LLM for contextual answers  
- ğŸ–¥ï¸ **Streamlit UI** with vintage-style theme for an interactive experience  
- ğŸ¤– **LLM Integration** â€“ supports **Ollama (Llama 3.2)** locally or **OpenAI** for faster cloud inference  
- ğŸ“Š **Document Similarity Search** with expandable context display  

---

## ğŸ› ï¸ Tech Stack  
- [Streamlit](https://streamlit.io/) â€“ UI  
- [LangChain](https://www.langchain.com/) â€“ Chaining & Retrieval  
- [FAISS](https://github.com/facebookresearch/faiss) â€“ Vector Store  
- [Ollama](https://ollama.ai/) / [OpenAI](https://openai.com/) â€“ LLMs  
- [Python-dotenv](https://pypi.org/project/python-dotenv/) â€“ Environment Management  

---

## ğŸ“‚ Project Structure  
